{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb764729-4eee-4291-9963-4cfd50158914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MISSING VALUE:\\n   Missing data, or missing values, occur when you don't have data stored for certain variables or participants. \\n   Data can go missing due to incomplete data entry, equipment malfunctions, lost files, and many other reasons. \\n   In any dataset, there are usually some missing data.\\n   \\n   ESSENTIAL TO HANDLE MISSING VALUE:\\n   The concept of missing values is important to understand in order to successfully manage data. If the missing values \\n   are not handled properly by the researcher, then he/she may end up drawing an inaccurate inference about the data.\\n   \\n   ALGORITHMS THAT ARE NOT AFFECTED BY MISSING VALUES:\\n   we will discuss machine learning algorithms that don't require handling the missing values explicitly:\\n   Histogram based Gradient-boosting Classifier / Regressor.\\n   \""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "'''MISSING VALUE:\n",
    "   Missing data, or missing values, occur when you don't have data stored for certain variables or participants. \n",
    "   Data can go missing due to incomplete data entry, equipment malfunctions, lost files, and many other reasons. \n",
    "   In any dataset, there are usually some missing data.\n",
    "   \n",
    "   ESSENTIAL TO HANDLE MISSING VALUE:\n",
    "   The concept of missing values is important to understand in order to successfully manage data. If the missing values \n",
    "   are not handled properly by the researcher, then he/she may end up drawing an inaccurate inference about the data.\n",
    "   \n",
    "   ALGORITHMS THAT ARE NOT AFFECTED BY MISSING VALUES:\n",
    "   we will discuss machine learning algorithms that don't require handling the missing values explicitly:\n",
    "   Histogram based Gradient-boosting Classifier / Regressor.\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ecb48d6-925d-4aa0-abd8-d04ad361e446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "''' THEIR ARE THREE METHODS TO HANDLE MISSING DATA:\n",
    "   1. MEAN\n",
    "   2. MEDIAN\n",
    "   3. MODE\n",
    "EXAMPLE:'''\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "704009a6-823a-4d41-bdaf-c708975dbd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_mean</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>29.699118</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age_mean   age\n",
       "0    22.000000  22.0\n",
       "1    38.000000  38.0\n",
       "2    26.000000  26.0\n",
       "3    35.000000  35.0\n",
       "4    35.000000  35.0\n",
       "..         ...   ...\n",
       "886  27.000000  27.0\n",
       "887  19.000000  19.0\n",
       "888  29.699118   NaN\n",
       "889  26.000000  26.0\n",
       "890  32.000000  32.0\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.MEAN METHOD USE MEAN VALUE TO FILL THE SPACE\n",
    "df['age_mean']=df['age'].fillna(df['age'].mean())\n",
    "df[['age_mean','age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c738a246-bb2b-449f-813c-cc8fffe5dd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_median</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age_median   age\n",
       "0          22.0  22.0\n",
       "1          38.0  38.0\n",
       "2          26.0  26.0\n",
       "3          35.0  35.0\n",
       "4          35.0  35.0\n",
       "..          ...   ...\n",
       "886        27.0  27.0\n",
       "887        19.0  19.0\n",
       "888        28.0   NaN\n",
       "889        26.0  26.0\n",
       "890        32.0  32.0\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.MEDIAN METHOD USE MEAN VALUE TO FILL THE SPACE\n",
    "df['age_median']=df['age'].fillna(df['age'].median())\n",
    "df[['age_median','age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd6939ca-3abc-4247-9d3d-f00b12a1c29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_mode</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age_mode   age\n",
       "0        22.0  22.0\n",
       "1        38.0  38.0\n",
       "2        26.0  26.0\n",
       "3        35.0  35.0\n",
       "4        35.0  35.0\n",
       "..        ...   ...\n",
       "886      27.0  27.0\n",
       "887      19.0  19.0\n",
       "888       NaN   NaN\n",
       "889      26.0  26.0\n",
       "890      32.0  32.0\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. MODE METHOD USE MEAN VALUE TO FILL THE SPACE\n",
    "df['age_mode']=df['age'].fillna(df['age'].mode())\n",
    "df[['age_mode','age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd05f74d-cce7-48f8-a5ff-89460c540c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IMBALANCED DATA:\\n   Imbalanced data refers to those types of datasets where the target class has an uneven distribution of observations, \\n   i.e one class label has a very high number of observations and the other has a very low number of observations.\\n    Example:\\n          like in a survey we found 85% people are health over 1000people\\n          it means 850are health and 150 are suffer with some disease.\\n          \\n    Imbalanced data set will lead algorithms to get good results by returning the majority. That will be a problem \\n    if you are interested in the minority more. So, balancing is a way to force the algorithm to give more weight to \\n    the minority.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "'''IMBALANCED DATA:\n",
    "   Imbalanced data refers to those types of datasets where the target class has an uneven distribution of observations, \n",
    "   i.e one class label has a very high number of observations and the other has a very low number of observations.\n",
    "    Example:\n",
    "          like in a survey we found 85% people are health over 1000people\n",
    "          it means 850are health and 150 are suffer with some disease.\n",
    "          \n",
    "    Imbalanced data set will lead algorithms to get good results by returning the majority. That will be a problem \n",
    "    if you are interested in the minority more. So, balancing is a way to force the algorithm to give more weight to \n",
    "    the minority.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9f98e8-6a0b-4ea4-a2bd-34922715dca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    850\n",
       "1    850\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4\n",
    "'''Up-Sampling is a \"Zero-Padding Procedure\" that increase the number of samples of a DT signal. More specificals,\n",
    "      when up sampling, zeros are added between the samples of a signal. \n",
    "   Down-Sampling is to decrease the sample size.\n",
    "       Downsampling is a mechanism that reduces the count of training samples falling under the majority class.\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "n_samples = 1000\n",
    "class_0_ratio = 0.85\n",
    "n_class_0 = int(n_samples * class_0_ratio)\n",
    "n_class_1 = n_samples - n_class_0\n",
    "\n",
    "class_0 = pd.DataFrame({\n",
    "    'feature_1': np.random.normal(loc=0, scale=1, size=n_class_0),\n",
    "    'feature_2': np.random.normal(loc=0, scale=1, size=n_class_0),\n",
    "    'target': [0] * n_class_0\n",
    "      })\n",
    "\n",
    "class_1 = pd.DataFrame({\n",
    "    'feature_1': np.random.normal(loc=2, scale=1, size=n_class_1),\n",
    "    'feature_2': np.random.normal(loc=2, scale=1, size=n_class_1),\n",
    "    'target': [1] * n_class_1\n",
    "      })\n",
    "df=pd.concat([class_0,class_1]).reset_index(drop=True)\n",
    "\n",
    "# example of up sampling\n",
    "df_minority=df[df['target']==1]\n",
    "df_majority=df[df['target']==0]\n",
    "\n",
    "from sklearn.utils import resample\n",
    "df_minority_upsampled=resample(df_minority,replace=True,\n",
    "         n_samples=len(df_majority),\n",
    "         random_state=42\n",
    "        )\n",
    "df_upsampled=pd.concat([df_majority,df_minority_upsampled])\n",
    "df_upsampled['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ec8b801-a68f-43d0-a332-b19694e90aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of down sampling\n",
    "from sklearn.utils import resample\n",
    "df_majority_upsampled=resample(df_minority,replace=True,\n",
    "         n_samples=len(df_majority),\n",
    "         random_state=42\n",
    "        )\n",
    "df_downsampled = pd.concat([df_minority,df_majority_upsampled])\n",
    "df_downsampled['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a6e1df4-be20-4f82-8297-388148914181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Data augmentation is a technique of artificially increasing the training set by creating modified copies of a\\n   dataset using existing data. It includes making minor changes to the dataset or using deep learning to generate new\\n   data points\\n   \\n   SMOTE (Synthetic Minority Over-sampling Technique) is a technique used in machine learning to address imbalanced\\n   datasets where the minority class has significantly fewer instances than the majority class. SMOTE involves generating\\n   synthetic instances of the minority class by interpolating between existing instances.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5\n",
    "''' Data augmentation is a technique of artificially increasing the training set by creating modified copies of a\n",
    "   dataset using existing data. It includes making minor changes to the dataset or using deep learning to generate new\n",
    "   data points\n",
    "   \n",
    "   SMOTE (Synthetic Minority Over-sampling Technique) is a technique used in machine learning to address imbalanced\n",
    "   datasets where the minority class has significantly fewer instances than the majority class. SMOTE involves generating\n",
    "   synthetic instances of the minority class by interpolating between existing instances.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceaa66ca-fa9f-4d8a-b916-3d1516f13f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An outlier is an observation that lies an abnormal distance from other values in a random sample from a population. \\n   In a sense, this definition leaves it up to the analyst (or a consensus process) to decide what will be considered \\n   abnormal.\\n   Outliers are important because they can have a large influence on statistics derived from the dataset.\\n   example: the mean intake of energy or some nutrient may be [glossary term:] skewed upward or downward by one or a \\n   few extreme values (Learn More about Normal Distributions).\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6\n",
    "'''An outlier is an observation that lies an abnormal distance from other values in a random sample from a population. \n",
    "   In a sense, this definition leaves it up to the analyst (or a consensus process) to decide what will be considered \n",
    "   abnormal.\n",
    "   Outliers are important because they can have a large influence on statistics derived from the dataset.\n",
    "   example: the mean intake of energy or some nutrient may be [glossary term:] skewed upward or downward by one or a \n",
    "   few extreme values (Learn More about Normal Distributions).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fa5944f-932c-4e79-8c78-16a3475b6b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"When dealing with missing data, data scientists can use two primary methods to solve the error:\\n1. imputation or \\n2. the removal of data.\\n\\n1. imputation:\\nThe imputation method develops reasonable guesses for missing data. It's most useful when the percentage of missing\\ndata is low.\\n2. removal:\\nRemoving data may not be the best option if there are not enough observations to result in a reliable analysis.\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7\n",
    "'''When dealing with missing data, data scientists can use two primary methods to solve the error:\n",
    "1. imputation or \n",
    "2. the removal of data.\n",
    "\n",
    "1. imputation:\n",
    "The imputation method develops reasonable guesses for missing data. It's most useful when the percentage of missing\n",
    "data is low.\n",
    "2. removal:\n",
    "Removing data may not be the best option if there are not enough observations to result in a reliable analysis.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e1d3dc-752d-4496-9413-60db42953283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Multiple imputation is another useful strategy for handling the missing data. In a multiple imputation, instead of\\nsubstituting a single value for each missing data, the missing values are replaced with a set of plausible values which \\ncontain the natural variability and uncertainty of the right values.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8\n",
    "'''Multiple imputation is another useful strategy for handling the missing data. In a multiple imputation, instead of\n",
    "substituting a single value for each missing data, the missing values are replaced with a set of plausible values which \n",
    "contain the natural variability and uncertainty of the right values.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35aec2a0-4ea1-4489-ba1d-85ef465ab024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we will see different techniques to handle imbalanced data.\\nSample Dataset. \\nRandom Under-Sampling.\\nRandom Over-Sampling.\\nRandom Under-Sampling With Imblearn.\\nRandom Over-Sampling With imblearn.\\nUnder-Sampling: Tomek Links. \\nSynthetic Minority Oversampling Technique (SMOTE)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q9\n",
    "'''we will see different techniques to handle imbalanced data.\n",
    "Sample Dataset. \n",
    "Random Under-Sampling.\n",
    "Random Over-Sampling.\n",
    "Random Under-Sampling With Imblearn.\n",
    "Random Over-Sampling With imblearn.\n",
    "Under-Sampling: Tomek Links. \n",
    "Synthetic Minority Oversampling Technique (SMOTE)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41c7f5aa-2025-47fd-8863-df271990789a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resampling (Oversampling and Undersampling)\\n   This technique is called oversampling. Similarly, we can randomly delete rows from the majority class to match them\\n   with the minority class which is called undersampling. After sampling the data we can get a balanced dataset for \\n   both majority and minority classes.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q10\n",
    "'''Resampling (Oversampling and Undersampling)\n",
    "   This technique is called oversampling. Similarly, we can randomly delete rows from the majority class to match them\n",
    "   with the minority class which is called undersampling. After sampling the data we can get a balanced dataset for \n",
    "   both majority and minority classes.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58809258-8345-4345-b732-bd4083ba82d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resampling (Oversampling and Undersampling)\\n   This technique is used to upsample or downsample the minority or majority class. When we are using an imbalanced \\n   dataset, we can oversample the minority class using replacement. This technique is called oversampling.\\n=>7 Techniques to Handle Imbalanced Data.\\nUse the right evaluation metrics.\\nResample the training set. \\nUse K-fold Cross-Validation in the Right Way.\\nEnsemble Different Resampled Datasets.\\nResample with Different Ratios.\\nCluster the abundant class.\\nDesign Your Models.\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q11\n",
    "'''Resampling (Oversampling and Undersampling)\n",
    "   This technique is used to upsample or downsample the minority or majority class. When we are using an imbalanced \n",
    "   dataset, we can oversample the minority class using replacement. This technique is called oversampling.\n",
    "=>7 Techniques to Handle Imbalanced Data.\n",
    "Use the right evaluation metrics.\n",
    "Resample the training set. \n",
    "Use K-fold Cross-Validation in the Right Way.\n",
    "Ensemble Different Resampled Datasets.\n",
    "Resample with Different Ratios.\n",
    "Cluster the abundant class.\n",
    "Design Your Models.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac6f03-f68b-4062-899b-b427690b8584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
